{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyOzT/xo09fH9NlKSOVnmRlY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8f4c83145c144e5aac59a496093fa1b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e559621173cf40249e49abcb37133fa4","IPY_MODEL_e36e01167b114b5d9552b46ef43e0174","IPY_MODEL_f5d8dc80416c46b6bc194278edbac800"],"layout":"IPY_MODEL_ad5e33dd68364580b32367ae43254ce1"}},"e559621173cf40249e49abcb37133fa4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ff1bc5af08a49b2a401446dd54432e0","placeholder":"​","style":"IPY_MODEL_62cf2ba3dd0447debec9f188f88652a4","value":"model.safetensors: 100%"}},"e36e01167b114b5d9552b46ef43e0174":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d67d8e9baea4af49b3da0cf6cdbf938","max":21355344,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fde762ee04e9493e80e437b237a8148a","value":21355344}},"f5d8dc80416c46b6bc194278edbac800":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e03bd04ca73c4cd38738f284bea9ca19","placeholder":"​","style":"IPY_MODEL_bd2827a799f14ddf8c4a1bf2574ec8b4","value":" 21.4M/21.4M [00:01&lt;00:00, 80.4kB/s]"}},"ad5e33dd68364580b32367ae43254ce1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ff1bc5af08a49b2a401446dd54432e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62cf2ba3dd0447debec9f188f88652a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d67d8e9baea4af49b3da0cf6cdbf938":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fde762ee04e9493e80e437b237a8148a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e03bd04ca73c4cd38738f284bea9ca19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd2827a799f14ddf8c4a1bf2574ec8b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Red Neuronal Convolucional - EfficientNet-B0 | 5.3 M Parametros"],"metadata":{"id":"ok29N9_MyyiU"}},{"cell_type":"markdown","source":["## Inputs"],"metadata":{"id":"VV8HrKLqzHQX"}},{"cell_type":"markdown","source":["### Instalación de librerias"],"metadata":{"id":"BoQF2PgJzKK0"}},{"cell_type":"code","source":["!pip install timm torchmetrics albumentations opencv-python astropy grad-cam\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OoH7vZjFON53","executionInfo":{"status":"ok","timestamp":1760485613378,"user_tz":360,"elapsed":29743,"user":{"displayName":"Diego Alvarado Marino","userId":"02323363341284917675"}},"outputId":"c5d607f2-9058-49f1-eccb-1091f1b4f668","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.20)\n","Collecting torchmetrics\n","  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n","Requirement already satisfied: astropy in /usr/local/lib/python3.12/dist-packages (7.1.0)\n","Collecting grad-cam\n","  Downloading grad-cam-1.5.5.tar.gz (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.35.3)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.16.2)\n","Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.11.10)\n","Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations) (4.12.0.88)\n","Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.2.0)\n","Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\n","Requirement already satisfied: pyerfa>=2.0.1.1 in /usr/local/lib/python3.12/dist-packages (from astropy) (2.0.1.5)\n","Requirement already satisfied: astropy-iers-data>=0.2025.4.28.0.37.27 in /usr/local/lib/python3.12/dist-packages (from astropy) (0.2025.10.6.0.35.25)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from grad-cam) (11.3.0)\n","Collecting ttach (from grad-cam)\n","  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from grad-cam) (4.67.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from grad-cam) (3.10.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from grad-cam) (1.6.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.20.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.1.10)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (1.4.9)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (2.9.0.post0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.10.5)\n","Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n","Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n","Building wheels for collected packages: grad-cam\n","  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for grad-cam: filename=grad_cam-1.5.5-py3-none-any.whl size=44284 sha256=03a90daab10a4384a14018aa38eb455928d7d59f3fa9eca35aa0937ba7cdbb75\n","  Stored in directory: /root/.cache/pip/wheels/fb/3b/09/2afc520f3d69bc26ae6bd87416759c820a3f7d05c1a077bbf6\n","Successfully built grad-cam\n","Installing collected packages: ttach, lightning-utilities, torchmetrics, grad-cam\n","Successfully installed grad-cam-1.5.5 lightning-utilities-0.15.2 torchmetrics-1.8.2 ttach-0.0.3\n"]}]},{"cell_type":"markdown","source":["### Librerias"],"metadata":{"id":"yP1qOvSnzMj0"}},{"cell_type":"code","source":["import os, math, random, json, glob\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from PIL import Image\n","import cv2\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn import functional as F\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from sklearn.metrics import average_precision_score, f1_score\n","from torchmetrics.classification import BinaryAUROC, BinaryCalibrationError\n","import timm\n","from astropy.io import fits\n","import cv2, numpy as np, pandas as pd\n","from torch.utils.data import Dataset\n","from astropy.io import fits\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from torch.utils.data import DataLoader\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from pytorch_grad_cam import GradCAM\n","from pytorch_grad_cam.utils.model_targets import BinaryClassifierOutputTarget\n","from pytorch_grad_cam.utils.image import show_cam_on_image\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import (\n","    classification_report,\n","    confusion_matrix,\n","    average_precision_score,\n","    roc_auc_score\n",")\n","from torch.utils.data import DataLoader\n","import torch\n","\n"],"metadata":{"id":"lKi160MTOBOj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SEED y GPU"],"metadata":{"id":"AozEnA9lzPiZ"}},{"cell_type":"code","source":["SEED = 42\n","random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"dBGSGhq7OdK2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Conexión con Google Drive"],"metadata":{"id":"akR1zCubzTnV"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdoG9fQEN-0c","executionInfo":{"status":"ok","timestamp":1760485664824,"user_tz":360,"elapsed":18261,"user":{"displayName":"Diego Alvarado Marino","userId":"02323363341284917675"}},"outputId":"15274518-8341-4a27-8670-e134babdc7cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## Procesamiento de Imagenes"],"metadata":{"id":"7UH1qY3fzZik"}},{"cell_type":"markdown","source":["### Procesamiento y apilado de imágenes astronómicas"],"metadata":{"id":"7YvRbx3CzvSM"}},{"cell_type":"markdown","source":["**Descripción**\n","\n","El código proporciona dos funciones principales:\n","- **read_band_image**: Lee imágenes astronómicas en formato FITS o PNG, normaliza los valores en el rango [0,1] y aplica un estirado asinh para mejorar el contraste de forma suave.\n","- **stack_bands**: Toma varias bandas (por defecto `g, r, z`), las centra y recorta a un formato cuadrado, las redimensiona a un tamaño fijo y finalmente las apila en un tensor con la forma C×H×W.\n","\n","**Técnicas utilizadas**\n","\n","- **Normalización por percentiles** (1%–99.5%) para limitar el rango dinámico y eliminar valores extremos.\n","- **Transformación asinh** con ganancia ≈10 para un contraste suave y balanceado entre regiones brillantes y débiles.\n","- **Conversión a escala de grises** para imágenes en color.\n","- **Centrado y padding a cuadrado** antes del escalado para evitar distorsiones geométricas.\n","- **Redimensionamiento conservador** con interpolación `INTER_AREA` para mantener la calidad en la reducción de tamaño.\n","- **Apilado de canales** con `np.stack` para generar un tensor multicanal adecuado para modelos de visión por computadora.\n","\n","**Justificación**\n","\n","- El **recorte por percentiles** evita que valores atípicos dominen la escala de intensidad.\n","- El **estirado asinh** es una técnica común en astrofotografía para resaltar estructuras débiles sin saturar las regiones brillantes.\n","- El **padding centrado** garantiza que la relación de aspecto se preserve antes del resize, evitando deformaciones.\n","- La **interpolación adecuada** mantiene la fidelidad visual al reducir la resolución.\n","- El **apilado en formato tensorial** prepara los datos para su uso en redes neuronales o pipelines de análisis de imágenes científicas."],"metadata":{"id":"fCNcwfx4z58A"}},{"cell_type":"code","source":["def read_band_image(path):\n","    # Lee FITS o PNG y devuelve float32 en [0,1] con asinh stretch controlado\n","    if path.endswith(\".fits\"):\n","        data = fits.getdata(path).astype(np.float32)\n","        data = np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)\n","    else:\n","        data = cv2.imread(path, cv2.IMREAD_UNCHANGED).astype(np.float32)\n","        if data.ndim==3: data = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n","    # recorte de percentiles y asinh\n","    lo, hi = np.percentile(data, [1, 99.5])\n","    if hi<=lo: hi = lo+1e-6\n","    data = np.clip((data - lo) / (hi - lo), 0, 1)\n","    data = np.arcsinh(10*data) / np.arcsinh(10)  # contraste suave\n","    return data\n","\n","def stack_bands(root, image_id, bands=(\"g\",\"r\",\"z\"), ext=\".fits\", size=256):\n","    chans = []\n","    for b in bands:\n","        p = f\"{root}/{b}/{image_id}{ext}\"\n","        if not os.path.exists(p):\n","            p = f\"{root}/{b}/{image_id}.png\"\n","        img = read_band_image(p)\n","        # centra/pad a cuadrado y resize conservador\n","        h,w = img.shape\n","        m = max(h,w)\n","        canvas = np.zeros((m,m), np.float32)\n","        y0 = (m-h)//2; x0 = (m-w)//2\n","        canvas[y0:y0+h, x0:x0+w] = img\n","        img = cv2.resize(canvas, (size,size), interpolation=cv2.INTER_AREA)\n","        chans.append(img)\n","    x = np.stack(chans, axis=0)  #\n","    return x\n"],"metadata":{"id":"ui1AWmIBOJ1F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset personalizado con imágenes astronómicas y Data Augmentation"],"metadata":{"id":"dlM1Riki0l_q"}},{"cell_type":"markdown","source":["**Descripción**\n","\n","Este código define un conjunto de utilidades y una clase `BarsDatasetPaths` para construir un **dataset de imágenes astronómicas** a partir de rutas explícitas en un archivo CSV.  \n","Incluye funciones auxiliares para:\n","- Leer imágenes FITS/PNG en escala de grises.\n","- Aplicar normalización de contraste mediante estirado asinh.\n","- Centrar, acolchar y redimensionar las imágenes a un tamaño uniforme.\n","- Apilar las bandas g, r, z en tensores.\n","Además, integra **transformaciones de data augmentation** (rotaciones, traslaciones, ruido, etc.) usando la librería Albumentations, y devuelve tensores junto con las etiquetas.\n","\n","**Técnicas utilizadas**\n","\n","- **Lectura robusta de FITS y PNG** con saneamiento de valores (NaN/Inf → 0).\n","- **Normalización por percentiles (1–99.5%)** para estabilizar el rango dinámico.\n","- **Transformación asinh** para resaltar detalles débiles sin saturar zonas brillantes.\n","- **Centrado y padding a cuadrado + resize** para homogenizar dimensiones de entrada.\n","- **Apilado de canales** g/r/z en formato tensorial.\n","- **Data augmentation con Albumentations**: rotaciones, traslaciones, desenfoque gaussiano, ruido gaussiano, y ajuste de brillo/contraste.\n","- **Conversión a tensores PyTorch** con `ToTensorV2`.\n","\n","**Justificación**\n","\n","- La **lectura multi-formato (FITS/PNG)** garantiza compatibilidad con diferentes fuentes de datos astronómicos.\n","- El **recorte por percentiles y estirado asinh** son técnicas estándar en astrofotografía para mejorar la visibilidad de estructuras astronómicas.\n","- El **padding y resize** evitan deformaciones geométricas y permiten entrenar modelos con entradas de tamaño fijo.\n","- El **apilado de bandas g/r/z** conserva la información multicanal relevante para análisis de galaxias y barras estelares.\n","- El uso de **augmentaciones** introduce variaciones realistas en los datos de entrenamiento, mejorando la capacidad de generalización del modelo.\n","- El diseño en forma de **Dataset de PyTorch** permite integrarse fácilmente en pipelines de entrenamiento con `DataLoader`."],"metadata":{"id":"l0Q9A-_g0yWH"}},{"cell_type":"code","source":["\n","def _read_fits_first2d(path):\n","    with fits.open(path, memmap=False) as hdul:\n","        for h in hdul:\n","            if h.data is not None and getattr(h.data, \"ndim\", 0)==2:\n","                arr = h.data.astype(np.float32); break\n","    return np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)\n","\n","def _read_any_gray(path):\n","    p = str(path).lower()\n","    if p.endswith(\".fits\") or p.endswith(\".fz\"):\n","        return _read_fits_first2d(path)\n","    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n","    if img is None: raise FileNotFoundError(path)\n","    if img.ndim==3: img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    return img.astype(np.float32)\n","\n","def _stretch_asinh(x):\n","    lo, hi = np.percentile(x, [1, 99.5])\n","    x = np.clip((x-lo)/(hi-lo+1e-6), 0, 1)\n","    return np.arcsinh(10*x)/np.arcsinh(10)\n","\n","def _pad_resize_square(img, size=256):\n","    h,w = img.shape; m = max(h,w)\n","    canvas = np.zeros((m,m), np.float32)\n","    y0=(m-h)//2; x0=(m-w)//2\n","    canvas[y0:y0+h, x0:x0+w] = img\n","    return cv2.resize(canvas, (size,size), interpolation=cv2.INTER_AREA)\n","\n","def stack_from_row(row, size=256):\n","    chans=[]\n","    for b in [\"g\",\"r\",\"z\"]:\n","        p = row[f\"path_{b}\"]\n","        img = _read_any_gray(p)\n","        img = _pad_resize_square(_stretch_asinh(img), size)\n","        chans.append(img)\n","    return np.stack(chans, axis=0)  # CxHxW\n","\n","def build_transforms(train=True):\n","    if train:\n","        return A.Compose([\n","            A.Rotate(limit=180, border_mode=cv2.BORDER_REFLECT_101, p=1.0),\n","            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.0, rotate_limit=0, border_mode=cv2.BORDER_REFLECT_101, p=0.5),\n","            A.GaussianBlur(blur_limit=(3,5), p=0.3),\n","            A.GaussNoise(var_limit=(1e-5,5e-4), p=0.3),\n","            A.RandomBrightnessContrast(0.05,0.05,p=0.3),\n","            ToTensorV2()\n","        ])\n","    else:\n","        return A.Compose([ToTensorV2()])\n","\n","class BarsDatasetPaths(Dataset):\n","    def __init__(self, csv_path, size=256, train=True):\n","        self.df = pd.read_csv(csv_path)\n","        self.size = size\n","        self.tfm = build_transforms(train)\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, i):\n","        r = self.df.iloc[i]\n","        x = stack_from_row(r, size=self.size)\n","        x = np.transpose(x, (1,2,0))\n","        x = self.tfm(image=x)[\"image\"]\n","        y_bin = torch.tensor(r.label_bin, dtype=torch.float32)\n","        y_str = torch.tensor(r.Bars,      dtype=torch.float32)\n","        return x, y_bin, y_str, r.image_id\n"],"metadata":{"id":"L-ZHub8puUBA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ds = BarsDatasetPaths(\"/content/drive/MyDrive/Proyecto_Integrador/Deteccion/datasets/train_grz.csv\", size=256, train=True)\n","x, yb, ys, _ = ds[0]\n","print(x.shape)  # debe ser torch.Size([3, 256, 256])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zPP7mVO8sLw9","executionInfo":{"status":"ok","timestamp":1760485786410,"user_tz":360,"elapsed":120851,"user":{"displayName":"Diego Alvarado Marino","userId":"02323363341284917675"}},"outputId":"0ce6bd7b-788a-4851-8df6-aa85dd7849f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n","  original_init(self, **validated_kwargs)\n","/tmp/ipython-input-3372821079.py:51: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n","  A.GaussNoise(var_limit=(1e-5,5e-4), p=0.3),\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([3, 256, 256])\n"]}]},{"cell_type":"markdown","source":["## Red Neuronal"],"metadata":{"id":"Jrd7YBta1KDg"}},{"cell_type":"markdown","source":["BarNet en PyTorch con EfficientNet como backbone y dos cabezas de predicción (binaria y continua)"],"metadata":{"id":"-p5aosbF1eKc"}},{"cell_type":"markdown","source":["**Descripción**\n","\n","La clase `BarNet` implementa un modelo de deep learning en PyTorch diseñado para analizar imágenes astronómicas multibanda.  \n","Se basa en un **backbone EfficientNet** (de la librería `timm`) para la extracción de características y añade dos cabezas totalmente conectadas:  \n","- `head_bin`: salida binaria (detección de presencia o ausencia de barras).  \n","- `head_str`: salida continua (estimación de la fuerza/intensidad de la barra).  \n","\n","El método `forward` obtiene las características del backbone y las procesa en paralelo por ambas cabezas para producir predicciones complementarias.\n","\n","**Técnicas utilizadas**\n","\n","- **Transfer learning con EfficientNet**: uso de `timm.create_model` con pesos preentrenados y adaptación de la entrada a 3 canales.  \n","- **Regularización** mediante `Dropout` y `DropPath` para reducir sobreajuste.  \n","- **Red neuronal secuencial** para las cabezas de predicción, con capas lineales, activación `ReLU` y dropout intermedio.  \n","- **Diseño multitarea**: dos salidas diferentes desde el mismo espacio de características (`logit` binario y `strength` continuo).  \n","\n","**Justificación**\n","\n","- El uso de **EfficientNet como backbone** aprovecha un modelo eficiente y potente para extraer representaciones visuales profundas de las imágenes astronómicas.  \n","- La **cabeza binaria** permite entrenar el modelo para una clasificación sencilla (¿existe o no una barra galáctica?).  \n","- La **cabeza continua** añade información más rica, cuantificando la intensidad de la barra, lo cual es útil para análisis más finos en astrofísica.  \n","- La **regularización con Dropout** y el uso de pesos preentrenados mejoran la generalización, evitando sobreajuste y acelerando la convergencia.  \n","- El **diseño multitarea** en un solo modelo es más eficiente y permite compartir representaciones entre tareas relacionadas.  \n"],"metadata":{"id":"kdE9mdkM1QLQ"}},{"cell_type":"code","source":["class BarNet(nn.Module):\n","    def __init__(self, backbone=\"tf_efficientnet_b0_ns\", in_chans=3, drop=0.2):\n","        super().__init__()\n","        self.backbone = timm.create_model(backbone, pretrained=True, in_chans=in_chans, drop_rate=drop, drop_path_rate=0.1, num_classes=0, global_pool=\"avg\")\n","        emb = self.backbone.num_features\n","        self.head_bin = nn.Sequential(nn.Linear(emb, 256), nn.ReLU(), nn.Dropout(0.2), nn.Linear(256,1))\n","        self.head_str = nn.Sequential(nn.Linear(emb, 256), nn.ReLU(), nn.Dropout(0.2), nn.Linear(256,1))\n","    def forward(self, x):\n","        feat = self.backbone(x)\n","        logit = self.head_bin(feat).squeeze(1)\n","        strength = self.head_str(feat).squeeze(1)\n","        return logit, strength\n"],"metadata":{"id":"jqRxmavoOpWM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Pérdidas, Métricas y ciclos de entrenamiento/validación"],"metadata":{"id":"UZ9d-gxZ1kaD"}},{"cell_type":"markdown","source":["**Descripción**\n","\n","Este bloque de código implementa:\n","- **`losses_and_metrics`**: calcula la función de pérdida combinada (clasificación binaria + regresión de fuerza) y métricas rápidas de evaluación por batch.\n","- **`train_one_epoch`**: ejecuta un ciclo de entrenamiento para una época, incluyendo cálculo de pérdidas, retropropagación, clipping de gradientes y optimización.\n","- **`validate`**: evalúa el modelo sin gradientes sobre un conjunto de validación, acumulando predicciones para calcular métricas globales.\n","\n","**Técnicas utilizadas**\n","\n","- **Binary Cross-Entropy (BCE)** con logits para la tarea de clasificación binaria (detección de barras).\n","- **Huber Loss** aplicada a la salida de fuerza (tras sigmoid) para manejar regresión robusta en el rango [0,1].\n","- **Combinación ponderada de pérdidas**: `loss = BCE + 0.5*Huber`.\n","- **Métricas de clasificación**: AUPRC (área bajo la curva de precisión-recall) y F1-score con umbral 0.5.\n","- **Métrica de regresión**: error absoluto medio (MAE) para la fuerza de la barra.\n","- **Entrenamiento supervisado estándar** en PyTorch: forward → loss → backward → optimización.\n","- **Regularización mediante gradient clipping** para evitar explosión de gradientes.\n","- **Validación sin gradientes** (`@torch.no_grad()`) para reducir memoria y acelerar inferencia.\n","\n","**Justificación**\n","\n","- La combinación de **BCE** y **Huber** refleja el enfoque multitarea del modelo: detección (binaria) y cuantificación (continua).\n","- El **Huber Loss** es más robusto frente a outliers que el MSE, lo que resulta adecuado en datos astronómicos con valores extremos.\n","- El cálculo de **AUPRC** es crítico en datasets desbalanceados, mientras que el **F1-score** aporta una métrica intuitiva en clasificación.\n","- El **MAE** ofrece una medida interpretable de error medio en la estimación de fuerza.\n","- El **clipping de gradientes** estabiliza el entrenamiento de redes profundas evitando actualizaciones inestables.\n","- La separación de funciones (`train_one_epoch` vs `validate`) promueve código limpio, modular y fácil de mantener en pipelines de entrenamiento.\n"],"metadata":{"id":"k4DLqgvN1rRX"}},{"cell_type":"code","source":["def losses_and_metrics(logit, strength_pred, y_bin, y_str):\n","    bce = F.binary_cross_entropy_with_logits(logit, y_bin)\n","    huber = F.huber_loss(torch.sigmoid(strength_pred), y_str)\n","    loss = bce + 0.5*huber\n","    prob = torch.sigmoid(logit).detach().cpu().numpy()\n","    yb = y_bin.detach().cpu().numpy()\n","    auprc = average_precision_score(yb, prob) if (yb.min()!=yb.max()) else np.nan\n","    f1 = f1_score((prob>=0.5).astype(int), yb.astype(int)) if (yb.min()!=yb.max()) else np.nan\n","    mae = np.mean(np.abs(torch.sigmoid(strength_pred).detach().cpu().numpy() - y_str.detach().cpu().numpy()))\n","    return loss, {\"auprc\":auprc, \"f1@0.5\":f1, \"mae_str\":mae}\n","\n","def train_one_epoch(model, loader, opt):\n","    model.train()\n","    logs=[]\n","    for x, yb, ys, _ in loader:\n","        x, yb, ys = x.to(device), yb.to(device), ys.to(device)\n","        opt.zero_grad()\n","        logit, sp = model(x)\n","        loss, _ = losses_and_metrics(logit, sp, yb, ys)\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n","        opt.step()\n","        logs.append(loss.item())\n","    return float(np.mean(logs))\n","\n","@torch.no_grad()\n","def validate(model, loader):\n","    model.eval()\n","    probs=[]; gts=[]; preds_str=[]; gts_str=[]\n","    for x, yb, ys, _ in loader:\n","        x = x.to(device)\n","        logit, sp = model(x)\n","        probs.append(torch.sigmoid(logit).cpu().numpy())\n","        preds_str.append(torch.sigmoid(sp).cpu().numpy())\n","        gts.append(yb.numpy()); gts_str.append(ys.numpy())\n","    prob = np.concatenate(probs); yb = np.concatenate(gts).astype(np.float32)\n","    sp = np.concatenate(preds_str); ys = np.concatenate(gts_str).astype(np.float32)\n","    auprc = average_precision_score(yb, prob) if (yb.min()!=yb.max()) else float(\"nan\")\n","    f1 = f1_score((prob>=0.5).astype(int), yb.astype(int)) if (yb.min()!=yb.max()) else float(\"nan\")\n","    mae = float(np.mean(np.abs(sp - ys)))\n","    return {\"val_auprc\":auprc, \"val_f1@0.5\":f1, \"val_mae_str\":mae}\n"],"metadata":{"id":"TF02TS1nOstz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Función de Entrenamiento"],"metadata":{"id":"y49YPzk-2Atr"}},{"cell_type":"markdown","source":["**Descripción**\n","\n","La función `fit_paths` implementa el ciclo de entrenamiento y validación para el modelo **BarNet** a partir de rutas CSV con datasets de entrenamiento y validación.  \n","Su flujo principal incluye:\n","1. Construcción de datasets (`BarsDatasetPaths`) y `DataLoader` para batching eficiente.\n","2. Creación del modelo `BarNet` con un backbone configurable.\n","3. Configuración del optimizador (`AdamW`) y scheduler de tasa de aprendizaje (`CosineAnnealingLR`).\n","4. Ejecución de múltiples épocas de entrenamiento con:\n","   - Forward y backward pass.\n","   - Cálculo de pérdidas y métricas.\n","   - Guardado de checkpoints (`last.pt` y `best.pt`).\n","   - Estrategia de **early stopping** basada en métricas de validación.\n","5. Retorno de la ruta al mejor modelo guardado.\n","\n","**Técnicas utilizadas**\n","\n","- **PyTorch DataLoader** con *multi-threading* (`num_workers=4`) y `pin_memory` para acelerar transferencia a GPU.\n","- **AdamW** como optimizador con regularización L2 vía `weight_decay`.\n","- **Cosine Annealing LR** para variar la tasa de aprendizaje de forma suave durante las épocas.\n","- **Validación periódica** con métricas (`val_auprc`, `val_f1`, `val_mae_str`).\n","- **Checkpointing** automático de los modelos (`last.pt` y `best.pt`) para reproducibilidad.\n","- **Early stopping** con paciencia configurable (6 épocas) para evitar sobreentrenamiento.\n","\n","**Justificación**\n","\n","- La construcción de datasets a partir de **CSV explícitos** permite trazabilidad de los datos de entrenamiento/validación.\n","- El uso de **AdamW** mejora la convergencia en visión por computadora frente al Adam estándar, especialmente con regularización adecuada.\n","- El **CosineAnnealingLR** proporciona un esquema de ajuste dinámico del learning rate que favorece estabilidad y evita mínimos locales.\n","- El **checkpointing** asegura la preservación de los mejores pesos incluso si el entrenamiento se interrumpe.\n","- La técnica de **early stopping** ahorra tiempo computacional y evita sobreajuste al detener el entrenamiento cuando el modelo deja de mejorar en validación.\n","- La función devuelve la ruta al mejor modelo (`best.pt`), facilitando su carga directa en fases posteriores de evaluación o inferencia.\n"],"metadata":{"id":"IW5LAx_H2DQn"}},{"cell_type":"code","source":["def fit_paths(csv_train, csv_val, size=256, in_chans=3, epochs=20, lr=2e-4, bs=32,\n","              backbone=\"tf_efficientnet_b0_ns\", out_dir=\"runs/barnet\"):\n","    os.makedirs(out_dir, exist_ok=True)\n","    tr_ds = BarsDatasetPaths(csv_train, size=size, train=True)\n","    va_ds = BarsDatasetPaths(csv_val,   size=size, train=False)\n","    tr = DataLoader(tr_ds, batch_size=bs, shuffle=True,  num_workers=4, pin_memory=True)\n","    va = DataLoader(va_ds, batch_size=bs, shuffle=False, num_workers=4, pin_memory=True)\n","\n","    model = BarNet(backbone=backbone, in_chans=in_chans).to(device)\n","    opt = AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n","    sch = CosineAnnealingLR(opt, T_max=epochs)\n","    best = -1; patience=6; bad=0\n","\n","    for ep in range(1, epochs+1):\n","        tr_loss = train_one_epoch(model, tr, opt)\n","        sch.step()\n","        m = validate(model, va)\n","        score = m[\"val_auprc\"]\n","        torch.save({\"model\":model.state_dict(),\"epoch\":ep,\"metrics\":m}, f\"{out_dir}/last.pt\")\n","        if score>best:\n","            best=score; bad=0\n","            torch.save({\"model\":model.state_dict(),\"epoch\":ep,\"metrics\":m}, f\"{out_dir}/best.pt\")\n","        else:\n","            bad += 1\n","        print(f\"[{ep}/{epochs}] loss {tr_loss:.4f} | {m}\")\n","        if bad>=patience:\n","            print(\"Early stop.\"); break\n","    return f\"{out_dir}/best.pt\"\n"],"metadata":{"id":"YoSWLe7NuewP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Threshold para clasificación binaria"],"metadata":{"id":"P3e-6hlv2O5v"}},{"cell_type":"markdown","source":["**Descripción**\n","\n","La función `pick_threshold` evalúa un modelo entrenado (`BarNet`) sobre un conjunto de datos para encontrar el **umbral de probabilidad** que maximiza el **F1-score** en la tarea binaria de detección de barras.  \n","El flujo es el siguiente:\n","1. Ejecuta el modelo en modo evaluación (`eval`) y desactiva el cálculo de gradientes (`@torch.no_grad`).\n","2. Recolecta las probabilidades predichas (`sigmoid(logit)`) y las etiquetas reales.\n","3. Recorre una grilla de posibles umbrales en el rango [0.2, 0.8].\n","4. Calcula el **F1-score** para cada umbral.\n","5. Devuelve el mejor umbral y su correspondiente valor de F1.\n","\n","**Técnicas utilizadas**\n","\n","- **Inferencia sin gradientes** (`torch.no_grad`) para optimizar memoria y velocidad.\n","- **Predicción de probabilidades** mediante la función sigmoide aplicada a logits.\n","- **Evaluación sistemática de umbrales** con búsqueda en rejilla (grid search) en pasos uniformes.\n","- **Métrica F1-score** como criterio de selección para balancear precisión y exhaustividad.\n","- **Concatenación de batches** en arrays NumPy para el cálculo global de métricas.\n","\n","**Justificación**\n","\n","- El umbral por defecto (0.5) puede no ser óptimo en datasets desbalanceados; este método ajusta el punto de decisión al conjunto de validación.\n","- La búsqueda en el rango [0.2–0.8] cubre escenarios donde las predicciones son más conservadoras o más liberales, permitiendo adaptar el modelo a las necesidades específicas.\n","- El **F1-score** se utiliza porque equilibra precisión y recall, lo cual es crítico en problemas donde detectar correctamente las barras astronómicas es más importante que minimizar un tipo específico de error.\n","- Seleccionar un **umbral óptimo validado** mejora la aplicabilidad práctica del modelo y la calidad de las predicciones en producción.\n"],"metadata":{"id":"1wCxd87F2VRv"}},{"cell_type":"code","source":["@torch.no_grad()\n","def pick_threshold(model, loader):\n","    model.eval()\n","    probs=[]; gts=[]\n","    for x, yb, _, _ in loader:\n","        x = x.to(device)\n","        logit, _ = model(x)\n","        probs.append(torch.sigmoid(logit).cpu().numpy())\n","        gts.append(yb.numpy())\n","    p = np.concatenate(probs); y = np.concatenate(gts).astype(int)\n","    best_f1, best_t = -1, 0.5\n","    for t in np.linspace(0.2,0.8,25):\n","        f1 = f1_score((p>=t).astype(int), y)\n","        if f1>best_f1: best_f1, best_t = f1, t\n","    return best_t, best_f1\n"],"metadata":{"id":"VbNYgJ1uPGGg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Interpretación de Predicciones"],"metadata":{"id":"8tzBYVLe2mJ4"}},{"cell_type":"markdown","source":["**Descripción**\n","\n","La función `gradcam_overlay` genera un **mapa de activación Grad-CAM** superpuesto sobre una imagen astronómica para interpretar qué regiones han influido en la decisión del modelo `BarNet`.  \n","El flujo es el siguiente:\n","1. Pone el modelo en modo evaluación.\n","2. Selecciona la capa objetivo para Grad-CAM:\n","   - Por defecto, la capa final del *backbone*.\n","   - Como alternativa, la última convolución disponible.\n","3. Calcula los mapas de activación Grad-CAM para la clase positiva (“con barra”).\n","4. Normaliza la imagen de entrada a rango [0,1].\n","5. Superpone el mapa de calor sobre la imagen en color para obtener una visualización interpretativa.\n","\n","**Técnicas utilizadas**\n","\n","- **Grad-CAM (Gradient-weighted Class Activation Mapping)** para identificar regiones relevantes de la imagen en la predicción.\n","- **Selección dinámica de la capa objetivo**: global pooling o última convolución.\n","- **Normalización de la entrada** a rango [0,1] para visualización adecuada.\n","- **Superposición de mapas de calor** (`show_cam_on_image`) para resaltar zonas de mayor activación.\n","- **Target específico de clase** mediante `BinaryClassifierOutputTarget`.\n","\n","**Justificación**\n","\n","- Grad-CAM proporciona **interpretabilidad** al modelo, mostrando en qué regiones de la galaxia se centra para detectar barras.\n","- La opción de elegir la **última capa convolucional** garantiza robustez, incluso si el *backbone* cambia.\n","- La **normalización y superposición** permiten producir visualizaciones claras y comparables entre distintas imágenes.\n","- El enfoque orientado a la clase positiva (“con barra”) es consistente con el objetivo científico: localizar evidencias de estructuras de barra en galaxias.\n","- Este tipo de visualización es esencial para validar que el modelo **aprende patrones astronómicamente relevantes** y no artefactos de los datos.\n"],"metadata":{"id":"ROa37Nlr2bg0"}},{"cell_type":"code","source":["\n","\n","def gradcam_overlay(model, x_tensor, target_layer=None):\n","    model.eval()\n","    if target_layer is None:\n","        # capa final del backbone\n","        target_layer = [model.backbone.get_global_pool().flatten]\n","        # fallback: usa la última conv si el backbone lo expone\n","        target_layer = [list(model.backbone.modules())[-2]]\n","    cam = GradCAM(model=model, target_layers=target_layer, use_cuda=(device.type==\"cuda\"))\n","    targets = [BinaryClassifierOutputTarget(1)]  # clase \"con barra\"\n","    grayscale_cam = cam(input_tensor=x_tensor, targets=targets)[0]\n","    img = x_tensor[0].permute(1,2,0).cpu().numpy()\n","    img = (img - img.min())/(img.max()-img.min()+1e-8)\n","    vis = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n","    return vis  # array RGB\n"],"metadata":{"id":"zrwvw2BhPHfg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ejecución de Entrenamiento"],"metadata":{"id":"y1lrG5Ex21tX"}},{"cell_type":"markdown","source":["- Tamaño de las imágenes (`256x256`).\n","- Número de canales de entrada (`3`).\n","- Número de épocas (`30`).\n","- Tasa de aprendizaje (`2e-4`).\n","- Batch size (`32`).\n","- Backbone (`tf_efficientnet_b0_ns`).\n","- Directorio de salida para checkpoints y logs.  "],"metadata":{"id":"ybDOj5nz24dE"}},{"cell_type":"code","source":["DATASETS_DIR = \"/content/drive/MyDrive/Proyecto_Integrador/Deteccion/datasets\"\n","ckpt = fit_paths(\n","    csv_train=f\"{DATASETS_DIR}/train_grz.csv\",\n","    csv_val  =f\"{DATASETS_DIR}/val_grz.csv\",\n","    size=256,\n","    in_chans=3,\n","    epochs=30,\n","    lr=2e-4,\n","    bs=32,\n","    backbone=\"tf_efficientnet_b0_ns\",\n","    out_dir=\"/content/drive/MyDrive/Proyecto_Integrador/Deteccion/runs/barnet\"\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8f4c83145c144e5aac59a496093fa1b9","e559621173cf40249e49abcb37133fa4","e36e01167b114b5d9552b46ef43e0174","f5d8dc80416c46b6bc194278edbac800","ad5e33dd68364580b32367ae43254ce1","6ff1bc5af08a49b2a401446dd54432e0","62cf2ba3dd0447debec9f188f88652a4","6d67d8e9baea4af49b3da0cf6cdbf938","fde762ee04e9493e80e437b237a8148a","e03bd04ca73c4cd38738f284bea9ca19","bd2827a799f14ddf8c4a1bf2574ec8b4"]},"id":"qoYwWRk5q1vp","executionInfo":{"status":"ok","timestamp":1759635234484,"user_tz":360,"elapsed":7690045,"user":{"displayName":"Diego Alvarado Marino","userId":"02323363341284917675"}},"outputId":"04013279-e6b6-4ce2-837c-f235203dd9cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n","  original_init(self, **validated_kwargs)\n","/tmp/ipython-input-346098372.py:51: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n","  A.GaussNoise(var_limit=(1e-5,5e-4), p=0.3),\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n","  model = create_fn(\n","/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f4c83145c144e5aac59a496093fa1b9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[1/30] loss 0.5779 | {'val_auprc': np.float64(0.7404105089035699), 'val_f1@0.5': 0.6617954070981211, 'val_mae_str': 0.2170836329460144}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[2/30] loss 0.5032 | {'val_auprc': np.float64(0.7813884579819502), 'val_f1@0.5': 0.7019438444924406, 'val_mae_str': 0.20218110084533691}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[3/30] loss 0.4643 | {'val_auprc': np.float64(0.8186184819976511), 'val_f1@0.5': 0.6353240152477764, 'val_mae_str': 0.18981438875198364}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[4/30] loss 0.4430 | {'val_auprc': np.float64(0.8196291378684212), 'val_f1@0.5': 0.717948717948718, 'val_mae_str': 0.19274495542049408}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[5/30] loss 0.4256 | {'val_auprc': np.float64(0.8330268357045476), 'val_f1@0.5': 0.7526205450733753, 'val_mae_str': 0.18001675605773926}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[6/30] loss 0.4083 | {'val_auprc': np.float64(0.8235113571118895), 'val_f1@0.5': 0.7456310679611651, 'val_mae_str': 0.1934792399406433}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[7/30] loss 0.3976 | {'val_auprc': np.float64(0.8359762710423013), 'val_f1@0.5': 0.7268817204301076, 'val_mae_str': 0.16959413886070251}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[8/30] loss 0.3887 | {'val_auprc': np.float64(0.8407712556055327), 'val_f1@0.5': 0.7494780793319415, 'val_mae_str': 0.16530153155326843}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[9/30] loss 0.3781 | {'val_auprc': np.float64(0.8445809755970861), 'val_f1@0.5': 0.7534391534391535, 'val_mae_str': 0.17087265849113464}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[10/30] loss 0.3649 | {'val_auprc': np.float64(0.8580303703261469), 'val_f1@0.5': 0.7619047619047619, 'val_mae_str': 0.1607305258512497}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[11/30] loss 0.3639 | {'val_auprc': np.float64(0.8648014729532498), 'val_f1@0.5': 0.7614973262032085, 'val_mae_str': 0.15838821232318878}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[12/30] loss 0.3630 | {'val_auprc': np.float64(0.858605012126083), 'val_f1@0.5': 0.7420814479638009, 'val_mae_str': 0.15424638986587524}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[13/30] loss 0.3486 | {'val_auprc': np.float64(0.8536365805746433), 'val_f1@0.5': 0.7409766454352441, 'val_mae_str': 0.1598677635192871}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[14/30] loss 0.3436 | {'val_auprc': np.float64(0.8563550113343033), 'val_f1@0.5': 0.757607555089192, 'val_mae_str': 0.16198404133319855}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[15/30] loss 0.3385 | {'val_auprc': np.float64(0.8628576119824565), 'val_f1@0.5': 0.7659574468085106, 'val_mae_str': 0.1580623835325241}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[16/30] loss 0.3274 | {'val_auprc': np.float64(0.8686257815506571), 'val_f1@0.5': 0.775, 'val_mae_str': 0.15609605610370636}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[17/30] loss 0.3213 | {'val_auprc': np.float64(0.8618467458140373), 'val_f1@0.5': 0.7625133120340788, 'val_mae_str': 0.15820549428462982}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[18/30] loss 0.3107 | {'val_auprc': np.float64(0.854649954140352), 'val_f1@0.5': 0.7693817468105987, 'val_mae_str': 0.16305133700370789}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[19/30] loss 0.3105 | {'val_auprc': np.float64(0.8603886287809441), 'val_f1@0.5': 0.7763975155279503, 'val_mae_str': 0.1587115228176117}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[20/30] loss 0.2935 | {'val_auprc': np.float64(0.8643271570838504), 'val_f1@0.5': 0.7804878048780488, 'val_mae_str': 0.15865790843963623}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[21/30] loss 0.2971 | {'val_auprc': np.float64(0.8627128741929073), 'val_f1@0.5': 0.7681592039800995, 'val_mae_str': 0.15848232805728912}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[22/30] loss 0.2839 | {'val_auprc': np.float64(0.8615089968434717), 'val_f1@0.5': 0.7693877551020408, 'val_mae_str': 0.15578590333461761}\n","Early stop.\n"]}]},{"cell_type":"markdown","source":["## Evaluación final del modelo BarNet\n"],"metadata":{"id":"T9zSz5GQ3Wlu"}},{"cell_type":"markdown","source":["Conjunto de test con métricas de clasificación, regresión y análisis de errores"],"metadata":{"id":"IBPYUt0r3cIQ"}},{"cell_type":"markdown","source":["**Descripción**\n","\n","Este bloque de código realiza la **evaluación completa del modelo BarNet** usando el conjunto de test.  \n","El flujo incluye:\n","1. **Carga del mejor modelo** (`best.pt`) con `weights_only=False` para restaurar pesos y estado del entrenamiento.\n","2. **Construcción del DataLoader de test** a partir de `test_grz.csv`.\n","3. **Predicción en inferencia** (`torch.no_grad`) para obtener:\n","   - Probabilidades (`probs`) y etiquetas predichas (`y_pred`).\n","   - Valores continuos de fuerza predicha (`strengths_pred`) y reales (`strengths_true`).\n","   - Identificadores de imagen (`image_ids`).\n","4. **Cálculo de métricas finales**:\n","   - Clasificación: Accuracy, Precisión, Recall, F1-score, AUPRC, AUROC.\n","   - Regresión: Error absoluto medio (MAE) en la fuerza de la barra.\n","   - Reporte de clasificación y matriz de confusión.\n","5. **Guardado de resultados detallados** en un CSV (`test_results.csv`) con etiquetas reales, predicciones, probabilidades y errores.\n","6. **Análisis de errores**: conteo de falsos positivos, falsos negativos y proporción total de errores.\n","\n","**Técnicas utilizadas**\n","\n","- **Carga de checkpoints** con `torch.load` y `load_state_dict` para restaurar el modelo entrenado.\n","- **Inferencia eficiente** con `torch.no_grad` para desactivar gradientes.\n","- **Evaluación de clasificación binaria** con métricas estándar: clasificación report, matriz de confusión, accuracy, precision, recall, F1, AUPRC y AUROC.\n","- **Evaluación de regresión** mediante MAE sobre la predicción de fuerza.\n","- **Análisis post-evaluación** separando errores en falsos positivos y falsos negativos.\n","- **Exportación de resultados** a CSV para trazabilidad y análisis posterior.\n","\n","**Justificación**\n","\n","- La **carga segura del modelo** garantiza reproducibilidad de los resultados sin necesidad de reentrenar.\n","- La **evaluación en test** proporciona una medida objetiva del desempeño final, independiente de los datos usados en entrenamiento y validación.\n","- El uso conjunto de **métricas de clasificación y regresión** refleja el carácter multitarea del modelo: detección binaria y cuantificación de fuerza.\n","- La **matriz de confusión** permite entender los tipos de errores (FP, FN), crucial para valorar la utilidad científica del modelo.\n","- Guardar las predicciones en un **CSV detallado** facilita auditoría, análisis de casos problemáticos y futuras visualizaciones.\n","- El **análisis de errores** da transparencia al desempeño del modelo, identificando en qué casos falla más y guiando mejoras futuras.\n"],"metadata":{"id":"0XQ6LiVR3hGL"}},{"cell_type":"code","source":["# 1. Cargar modelo con weights_only=False\n","DATASETS_DIR = \"/content/drive/MyDrive/Proyecto_Integrador/Deteccion/datasets\"\n","BEST = \"/content/drive/MyDrive/Proyecto_Integrador/Deteccion/runs/barnet/best.pt\"\n","\n","# Cargar checkpoint\n","ckpt = torch.load(BEST, map_location=device, weights_only=False)\n","model.load_state_dict(ckpt[\"model\"])\n","model.eval()\n","\n","print(\"Modelo cargado exitosamente\")\n","\n","# 2. Preparar test loader\n","TEST_CSV = f\"{DATASETS_DIR}/test_grz.csv\"\n","test_ds = BarsDatasetPaths(TEST_CSV, size=256, train=False)\n","test_dl = DataLoader(test_ds, batch_size=64, num_workers=2, pin_memory=True)\n","\n","# 3. Predecir\n","probs = []\n","y_true = []\n","strengths_pred = []\n","strengths_true = []\n","image_ids = []\n","\n","with torch.no_grad():\n","    for x, yb, ys, img_id in test_dl:\n","        x = x.to(device)\n","        logits, sp = model(x)\n","\n","        probs.append(torch.sigmoid(logits).cpu().numpy())\n","        y_true.append(yb.numpy())\n","        strengths_pred.append(torch.sigmoid(sp).cpu().numpy())\n","        strengths_true.append(ys.numpy())\n","        image_ids.extend(img_id)\n","\n","probs = np.concatenate(probs)\n","y_true = np.concatenate(y_true).astype(int)\n","y_pred = (probs >= 0.5).astype(int)\n","strengths_pred = np.concatenate(strengths_pred)\n","strengths_true = np.concatenate(strengths_true)\n","\n","# 4. METRICAS FINALES\n","print(\"=\"*60)\n","print(\"           RESULTADOS EN TEST SET\")\n","print(\"=\"*60)\n","\n","# Clasificacion\n","print(\"\\nReporte de Clasificacion:\")\n","print(classification_report(y_true, y_pred,\n","                          target_names=[\"Sin barra (0)\", \"Con barra (1)\"],\n","                          digits=4))\n","\n","# Matriz de confusion\n","print(\"\\nMatriz de Confusion:\")\n","cm = confusion_matrix(y_true, y_pred)\n","print(f\"                Pred: Sin barra | Con barra\")\n","print(f\"Real: Sin barra       {cm[0,0]:4d}        {cm[0,1]:4d}\")\n","print(f\"      Con barra       {cm[1,0]:4d}        {cm[1,1]:4d}\")\n","\n","tn, fp, fn, tp = cm.ravel()\n","accuracy = (tp + tn) / (tp + tn + fp + fn)\n","precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n","f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n","\n","print(f\"\\nMetricas Agregadas:\")\n","print(f\"  Accuracy:  {accuracy:.4f}\")\n","print(f\"  Precision: {precision:.4f}\")\n","print(f\"  Recall:    {recall:.4f}\")\n","print(f\"  F1-Score:  {f1:.4f}\")\n","print(f\"  AUPRC:     {average_precision_score(y_true, probs):.4f}\")\n","print(f\"  AUROC:     {roc_auc_score(y_true, probs):.4f}\")\n","\n","# Error en fuerza\n","mae_strength = np.mean(np.abs(strengths_pred - strengths_true))\n","print(f\"  MAE (fuerza): {mae_strength:.4f}\")\n","\n","# 5. Guardar predicciones\n","results = pd.DataFrame({\n","    'image_id': image_ids,\n","    'true_label': y_true,\n","    'pred_prob': probs,\n","    'pred_label': y_pred,\n","    'true_strength': strengths_true,\n","    'pred_strength': strengths_pred,\n","    'correct': y_true == y_pred,\n","    'error': np.abs(y_true - y_pred)\n","})\n","\n","OUT_CSV = f\"{DATASETS_DIR}/test_results.csv\"\n","results.to_csv(OUT_CSV, index=False)\n","print(f\"\\nGuardado: {OUT_CSV}\")\n","\n","# 6. Analisis de errores\n","errors = results[~results['correct']]\n","print(f\"\\nErrores: {len(errors)}/{len(results)} ({100*len(errors)/len(results):.2f}%)\")\n","\n","fp_errors = errors[errors['true_label'] == 0]\n","print(f\"  Falsos Positivos: {len(fp_errors)}\")\n","\n","fn_errors = errors[errors['true_label'] == 1]\n","print(f\"  Falsos Negativos: {len(fn_errors)}\")\n","\n","print(\"\\nEvaluacion completa.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mGzr7xGqMILg","executionInfo":{"status":"ok","timestamp":1760488081314,"user_tz":360,"elapsed":966290,"user":{"displayName":"Diego Alvarado Marino","userId":"02323363341284917675"}},"outputId":"5a12f1b8-be9e-498d-ec0f-d838b01eff26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Modelo cargado exitosamente\n","============================================================\n","           RESULTADOS EN TEST SET\n","============================================================\n","\n","Reporte de Clasificacion:\n","               precision    recall  f1-score   support\n","\n","Sin barra (0)     0.8705    0.9056    0.8877      1017\n","Con barra (1)     0.7918    0.7271    0.7580       502\n","\n","     accuracy                         0.8466      1519\n","    macro avg     0.8311    0.8163    0.8229      1519\n"," weighted avg     0.8445    0.8466    0.8449      1519\n","\n","\n","Matriz de Confusion:\n","                Pred: Sin barra | Con barra\n","Real: Sin barra        921          96\n","      Con barra        137         365\n","\n","Metricas Agregadas:\n","  Accuracy:  0.8466\n","  Precision: 0.7918\n","  Recall:    0.7271\n","  F1-Score:  0.7580\n","  AUPRC:     0.8693\n","  AUROC:     0.9210\n","  MAE (fuerza): 0.1541\n","\n","Guardado: /content/drive/MyDrive/Proyecto_Integrador/Deteccion/datasets/test_results.csv\n","\n","Errores: 233/1519 (15.34%)\n","  Falsos Positivos: 96\n","  Falsos Negativos: 137\n","\n","Evaluacion completa.\n"]}]}]}